{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Auto Encoder for Anomaly Detection with Custom Layer for determining Encoder Decoder Reconstruction Cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Necessary Files and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Embedding, Input, Dense, LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import optimizers\n",
    "import pickle\n",
    "import os\n",
    "from keras.layers import initializers \n",
    "from keras.layers import regularizers \n",
    "from keras.layers import constraints \n",
    "from keras.layers import Activation\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.constraints import max_norm\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, \\\n",
    "    concatenate\n",
    "from keras.layers import MaxPooling2D, Flatten, Conv2D\n",
    "from keras.utils import to_categorical\n",
    "initializer1 = keras.initializers.RandomNormal\n",
    "initializer2 = keras.initializers.Zeros()\n",
    "initializer3 = keras.initializers.glorot_uniform(seed=None)\n",
    "initializer4 = keras.initializers.lecun_normal(seed=None)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 29)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")\n",
    "\n",
    "# Try removing both Time and Amount for now\n",
    "# Amount could become a category cluster or could be normalized\n",
    "data.drop(\"Time\", inplace=True, axis=1)\n",
    "data.drop(\"Amount\", inplace=True, axis=1)\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...         V20       V21       V22  \\\n",
       "0  0.098698  0.363787  0.090794  ...    0.251412 -0.018307  0.277838   \n",
       "1  0.085102 -0.255425 -0.166974  ...   -0.069083 -0.225775 -0.638672   \n",
       "2  0.247676 -1.514654  0.207643  ...    0.524980  0.247998  0.771679   \n",
       "3  0.377436 -1.387024 -0.054952  ...   -0.208038 -0.108300  0.005274   \n",
       "4 -0.270533  0.817739  0.753074  ...    0.408542 -0.009431  0.798278   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  Class  \n",
       "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  \n",
       "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724      0  \n",
       "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  \n",
       "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  \n",
       "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153      0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 29) (492, 29) (284315, 29) 284807\n"
     ]
    }
   ],
   "source": [
    "all = data\n",
    "positive = data[data[\"Class\"] > 0]\n",
    "negative = data[data[\"Class\"] == 0]\n",
    "\n",
    "print(all.shape, positive.shape, negative.shape, positive.shape[0] + negative.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 28) (492, 28) (284315, 28) 284807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "all.drop(\"Class\", inplace=True, axis=1)\n",
    "positive.drop(\"Class\", inplace=True, axis=1)\n",
    "negative.drop(\"Class\", inplace=True, axis=1)\n",
    "\n",
    "print(all.shape, positive.shape, negative.shape, positive.shape[0] + negative.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive is the anomalies - Train AutoEncoder with Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = negative.shape[1]\n",
    "AUTO_ENCODER_SHAPE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255883, 28) (28432, 28) (255883, 1) 28 284315\n"
     ]
    }
   ],
   "source": [
    "train_size = int(negative.shape[0]*90/100)\n",
    "negative = negative.sample(frac=1)\n",
    "X_train = negative.iloc[:train_size]\n",
    "X_test = negative.iloc[-(negative.shape[0] - train_size):]\n",
    "\n",
    "# force the model to lower the autoencoder reconstruction cost\n",
    "Y = np.zeros([X_train.shape[0], 1], dtype = float) # ZEROS MATRIX with shape (,1)\n",
    "\n",
    "print(X_train.shape, X_test.shape, Y.shape, INPUT_SIZE, X_train.shape[0] + X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(INPUT_SIZE,))\n",
    "\n",
    "input_encoder = layers.Dense(AUTO_ENCODER_SHAPE, activation = 'relu')(input)\n",
    "hidden2 = layers.Dense(64, activation = 'relu')(input_encoder)\n",
    "encoded = layers.Dense(32, activation = 'relu')(hidden2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden3 = Dense(64, activation='relu')(encoded)\n",
    "output_decoder = Dense(AUTO_ENCODER_SHAPE, activation='relu')(hidden3)\n",
    "# decoded = Dense(100, activation='relu')(output_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "\n",
    "class ReconstructionCostLayer(Layer):\n",
    "\n",
    "    def __init__(self,output_dim):\n",
    "        self.output_dim = output_dim\n",
    "        super(ReconstructionCostLayer, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ReconstructionCostLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        left = K.slice(x, [0, 0], [-1, AUTO_ENCODER_SHAPE])\n",
    "        right = K.slice(x, [0, AUTO_ENCODER_SHAPE], [-1, -1])\n",
    "        return K.sum(K.square(left - right), axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate Encoder input and Decoder output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoder_plus_output_decoder = layers.concatenate([input_encoder, output_decoder], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the custom layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_cost_layer = ReconstructionCostLayer(1)(input_encoder_plus_output_decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the AutoEncoder with Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input, reconstruction_cost_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(lr=0.003, beta_1=0.9, beta_2=0.999, epsilon=1e-4, decay=0.0, amsgrad=True)\n",
    "model.compile(optimizer=adam, loss='mean_squared_error', metrics=['mse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          3712        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           2080        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           2112        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          8320        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           dense_1[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reconstruction_cost_layer_1 (Re (None, 1)            0           concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 24,480\n",
      "Trainable params: 24,480\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 24.8354 - mean_squared_error: 24.8354\n",
      "Epoch 2/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 1.9554 - mean_squared_error: 1.9554\n",
      "Epoch 3/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.3017 - mean_squared_error: 0.3017\n",
      "Epoch 4/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.1115 - mean_squared_error: 0.1115\n",
      "Epoch 5/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0669 - mean_squared_error: 0.0669\n",
      "Epoch 6/200\n",
      "255883/255883 [==============================] - 6s 23us/step - loss: 0.0505 - mean_squared_error: 0.0505\n",
      "Epoch 7/200\n",
      "255883/255883 [==============================] - 6s 22us/step - loss: 0.0405 - mean_squared_error: 0.0405\n",
      "Epoch 8/200\n",
      "255883/255883 [==============================] - 6s 23us/step - loss: 0.0333 - mean_squared_error: 0.0333\n",
      "Epoch 9/200\n",
      "255883/255883 [==============================] - 6s 23us/step - loss: 0.0284 - mean_squared_error: 0.0284\n",
      "Epoch 10/200\n",
      "255883/255883 [==============================] - 6s 23us/step - loss: 0.0245 - mean_squared_error: 0.0245\n",
      "Epoch 11/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0216 - mean_squared_error: 0.0216\n",
      "Epoch 12/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0192 - mean_squared_error: 0.0192\n",
      "Epoch 13/200\n",
      "255883/255883 [==============================] - 6s 25us/step - loss: 0.0172 - mean_squared_error: 0.0172\n",
      "Epoch 14/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0159 - mean_squared_error: 0.0159\n",
      "Epoch 15/200\n",
      "255883/255883 [==============================] - 6s 23us/step - loss: 0.0144 - mean_squared_error: 0.0144\n",
      "Epoch 16/200\n",
      "255883/255883 [==============================] - 6s 23us/step - loss: 0.0132 - mean_squared_error: 0.0132\n",
      "Epoch 17/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0122 - mean_squared_error: 0.0122\n",
      "Epoch 18/200\n",
      "255883/255883 [==============================] - 6s 23us/step - loss: 0.0114 - mean_squared_error: 0.0114\n",
      "Epoch 19/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0106 - mean_squared_error: 0.0106\n",
      "Epoch 20/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0100 - mean_squared_error: 0.0100\n",
      "Epoch 21/200\n",
      "255883/255883 [==============================] - 6s 23us/step - loss: 0.0094 - mean_squared_error: 0.0094\n",
      "Epoch 22/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0092 - mean_squared_error: 0.0092\n",
      "Epoch 23/200\n",
      "255883/255883 [==============================] - 6s 23us/step - loss: 0.0085 - mean_squared_error: 0.0085\n",
      "Epoch 24/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0081 - mean_squared_error: 0.0081\n",
      "Epoch 25/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0076 - mean_squared_error: 0.0076\n",
      "Epoch 26/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0073 - mean_squared_error: 0.0073\n",
      "Epoch 27/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0070 - mean_squared_error: 0.0070\n",
      "Epoch 28/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 29/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0064 - mean_squared_error: 0.0064\n",
      "Epoch 30/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0061 - mean_squared_error: 0.0061\n",
      "Epoch 31/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0059 - mean_squared_error: 0.0059\n",
      "Epoch 32/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Epoch 33/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 34/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 35/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 36/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 37/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 38/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 39/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 40/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 41/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 42/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 43/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 44/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 45/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 46/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 47/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 48/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 49/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 50/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 51/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 52/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 53/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 54/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 55/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 56/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 57/200\n",
      "255883/255883 [==============================] - 6s 24us/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 58/200\n",
      " 28900/255883 [==>...........................] - ETA: 5s - loss: 0.0027 - mean_squared_error: 0.0027"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b18117b41c2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtbCallBack\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                    )  \n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='./Graph', \n",
    "                                         histogram_freq=0, \n",
    "                                         write_graph=True, \n",
    "                                         write_images=True)\n",
    "\n",
    "history = model.fit(X_train, Y, epochs=200, batch_size=50, \n",
    "                    verbose=1,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[tbCallBack],\n",
    "                   )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Negative (Trained) Reconstruction Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 1\n",
    "\n",
    "def report_cost(result):\n",
    "    tot = len(result)\n",
    "    greater = len(np.where(result > THRESHOLD)[0])\n",
    "    print(\"Count: {}\\nGreater Than Threeshold: {} {}%\\nMean: {}\\nStd: {}\\nMin: {}\\nMax: {}\"\\\n",
    "          .format(tot,\n",
    "                  greater,\n",
    "                  (tot - greater) * 100 / tot,\n",
    "                  result.mean(),\n",
    "                  result.std(),\n",
    "                  result.min(),\n",
    "                  result.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 255883\n",
      "Greater Than Threeshold: 27 99.98944830254452%\n",
      "Mean: 0.025433020666241646\n",
      "Std: 0.04706026613712311\n",
      "Min: 0.0\n",
      "Max: 2.513159990310669\n"
     ]
    }
   ],
   "source": [
    "reconstruction_costs = model.predict(X_train)\n",
    "report_cost(reconstruction_costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# unique, counts = np.unique(reconstruction_costs, return_counts=True)\n",
    "# dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Negative (New) Reconstruction Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 28432\n",
      "Greater Than Threeshold: 2 99.99296567248172%\n",
      "Mean: 0.025260085240006447\n",
      "Std: 0.045378364622592926\n",
      "Min: 0.0\n",
      "Max: 1.1758919954299927\n"
     ]
    }
   ],
   "source": [
    "reconstruction_costs = model.predict(X_test)\n",
    "report_cost(reconstruction_costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# unique, counts = np.unique(reconstruction_costs, return_counts=True)\n",
    "# dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Positive Reconstruction Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 492\n",
      "Greater Than Threeshold: 68 86.17886178861788%\n",
      "Mean: 0.5795853734016418\n",
      "Std: 1.5153045654296875\n",
      "Min: 0.0\n",
      "Max: 13.82332992553711\n"
     ]
    }
   ],
   "source": [
    "reconstruction_costs = model.predict(positive)\n",
    "report_cost(reconstruction_costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique, counts = np.unique(reconstruction_costs, return_counts=True)\n",
    "# dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
